{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.random as jr\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import equinox.nn as nn\n",
    "import optax\n",
    "from model import GPTLanguageModel, encode, decode\n",
    "from typing import Optional, Tuple\n",
    "from train import load, get_batch, hyperparams\n",
    "\n",
    "KVCacheType = Optional[Tuple[jnp.ndarray, jnp.ndarray]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 256\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 3e-4\n",
    "max_epochs = 5000\n",
    "eval_interval = 500\n",
    "eval_iters = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTLanguageModel(key=jr.PRNGKey(0), **hyperparams)\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(model, opt_state, xb, yb):\n",
    "        print('update', xb.shape, yb.shape)\n",
    "        logits, loss, grads = model(xb, yb) \n",
    "        # compute gradients\n",
    "\n",
    "        # apply updates based on grads\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        model = eqx.apply_updates(model, updates) # update model\n",
    "        return loss, model, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update (64, 256) (64, 256)\n",
      "(256,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(model, opt_state, xb, yb)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(model, opt_state, xb, yb):\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m'\u001b[39m, xb\u001b[38;5;241m.\u001b[39mshape, yb\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m         logits, loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# compute gradients\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# apply updates based on grads\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         updates, opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grads, opt_state)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/dev/ai_space/nanogpt_jax/model.py:174\u001b[0m, in \u001b[0;36mGPTLanguageModel.__call__\u001b[0;34m(self, idx, targets, use_cache, blocks_kvcache)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: jnp\u001b[38;5;241m.\u001b[39mndarray, targets: Optional[jnp\u001b[38;5;241m.\u001b[39mndarray]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_cache: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, blocks_kvcache: List[KVCacheType]\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m n_layer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[jnp\u001b[38;5;241m.\u001b[39mndarray, Optional[jnp\u001b[38;5;241m.\u001b[39mndarray], List[KVCacheType]]:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks_kvcache\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/dev/ai_space/nanogpt_jax/model.py:178\u001b[0m, in \u001b[0;36mGPTLanguageModel.forward\u001b[0;34m(self, idx, targets, use_cache, blocks_kvcache)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m (\u001b[38;5;28mself\u001b[39m, idx: jnp\u001b[38;5;241m.\u001b[39mndarray, targets: Optional[jnp\u001b[38;5;241m.\u001b[39mndarray]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_cache: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, blocks_kvcache: List[KVCacheType]\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m n_layer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[jnp\u001b[38;5;241m.\u001b[39mndarray, Optional[jnp\u001b[38;5;241m.\u001b[39mndarray], List[KVCacheType]]:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mprint\u001b[39m(idx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 178\u001b[0m     B, T \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    179\u001b[0m     tok_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding_table(idx)\n\u001b[1;32m    180\u001b[0m     history_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocks_kvcache[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m blocks_kvcache[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "update(model, opt_state, xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gpt_model.eqx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt_model.eqx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/ai_space/nanogpt_jax/train.py:56\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(filename):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     57\u001b[0m         hyperparams \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(f\u001b[38;5;241m.\u001b[39mreadline()\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m     58\u001b[0m         model \u001b[38;5;241m=\u001b[39m make(key\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhyperparams)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gpt_model.eqx'"
     ]
    }
   ],
   "source": [
    "model = load(\"gpt_model.eqx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Togerous before them, after would those thrifts;\n",
      "Yield these have I look not how they there is no.\n",
      "Come, let's upon the desire\n",
      "Be count in affection. My noble looking throw\n",
      "Grows all.\n",
      "\n",
      "Lord:\n",
      "We thank that Paris to him.\n",
      "\n",
      "FLORIZEL:\n",
      "For child, be but long.\n",
      "\n",
      "P\n"
     ]
    }
   ],
   "source": [
    "start_str = \"\\n\"\n",
    "idx = jnp.array(encode(start_str)).reshape(1, -1)\n",
    "print(decode(model.generate(idx, max_new_tokens=256)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
